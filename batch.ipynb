{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from math import ceil\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"dataset\\train.csv\"\n",
    "df= pd.read_csv(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticketNo(ticketStr):\n",
    "    if isinstance(ticketStr, str):\n",
    "        noStr = re.findall(r\"[0-9]*$\", ticketStr)[0]\n",
    "        if noStr.isnumeric():\n",
    "            return int(noStr)\n",
    "    return np.nan\n",
    "\n",
    "def ticketTxt(ticketStr):\n",
    "    if isinstance(ticketStr, str):\n",
    "        noStr = re.findall(r\"[0-9]*$\", ticketStr)[0]\n",
    "        return ticketStr[:-len(noStr)]\n",
    "    return np.nan\n",
    "\n",
    "df[\"ticketNo\"] = df[\"Ticket\"].apply(ticketNo)\n",
    "df[\"ticketTxt\"] = df[\"Ticket\"].apply(ticketTxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cabinNo(cabinStr):\n",
    "    if isinstance(cabinStr, str):\n",
    "        return re.findall(r\"[0-9]*$\", cabinStr)[0]\n",
    "    return np.nan\n",
    "\n",
    "def cabinLvl(cabinStr):\n",
    "    if isinstance(cabinStr, str):\n",
    "        return re.findall(r\"^[A-Z]\", cabinStr)[0]\n",
    "    return np.nan\n",
    "\n",
    "df[\"cabinLvl\"] = df[\"Cabin\"].apply(cabinLvl)\n",
    "df[\"cabinNo\"] = df[\"Cabin\"].apply(cabinNo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title(name):\n",
    "    if isinstance(name, str):\n",
    "        return re.findall(r\"\\b\\w*\\.\", name)[0]\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "df[\"surname\"] = df[\"Name\"].apply(lambda x: x.split(\",\")[0])\n",
    "df[\"withChild\"] = df[\"Name\"].apply(lambda x: \"(\" in x)\n",
    "df[\"title\"] = df[\"Name\"].apply(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Categorical Features\n",
    "for col in df.columns:\n",
    "    if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "        df[col] = df[col].map({key: val for val, key in enumerate(df[col].unique())})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeler(df, target, drop=None, n=1, testSize=0.3, preProcess=None, algo=DummyClassifier(), metric=accuracy_score):\n",
    "    dfi = df.copy()\n",
    "    if drop:\n",
    "        dfi = dfi.drop(columns=drop)\n",
    "    \n",
    "    X = dfi.drop(columns=[target])\n",
    "    y= dfi[target]\n",
    "    results = []\n",
    "    \n",
    "    for train, test in KFold(n_splits=n, shuffle=True, random_state=42).split(X, y):\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "        if preProcess:\n",
    "            X_train = preProcess.fit_transform(X_train)\n",
    "            X_test = preProcess.transform(X_test)\n",
    "        algo.fit(X_train, y_train)\n",
    "        results.append(metric(y_test, algo.predict(X_test)))\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [\"ticketNo\", \"ticketTxt\", \"cabinLvl\", \"cabinNo\", \"surname\", \"withChild\",]\n",
    "dropsets = []\n",
    "for i in range(len(options)+1):\n",
    "    for combo in combinations(options, i):\n",
    "        combo = list(combo)\n",
    "        combo.extend([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"])\n",
    "        dropsets.append(combo)\n",
    "\n",
    "preProcessors = [\n",
    "    make_pipeline(StandardScaler(), SimpleImputer()),\n",
    "    make_pipeline(StandardScaler(), SimpleImputer(strategy=\"median\")),\n",
    "    make_pipeline(StandardScaler(), SimpleImputer(strategy=\"most_frequent\")),\n",
    "    make_pipeline(StandardScaler(), SimpleImputer(strategy=\"constant\", fill_value=-1)),\n",
    "    make_pipeline(RobustScaler(), SimpleImputer()),\n",
    "    make_pipeline(RobustScaler(), SimpleImputer(strategy=\"median\")),\n",
    "    make_pipeline(RobustScaler(), SimpleImputer(strategy=\"most_frequent\")),\n",
    "    make_pipeline(RobustScaler(), SimpleImputer(strategy=\"constant\", fill_value=-1)),\n",
    "]\n",
    "\n",
    "algos = [\n",
    "    GradientBoostingClassifier()\n",
    "]\n",
    "\n",
    "configs = []\n",
    "for dropset in dropsets:\n",
    "    for preProc in preProcessors:\n",
    "        for algo in algos:\n",
    "            configs.append({\n",
    "                \"drop\": dropset,\n",
    "                \"preProcess\": preProc,\n",
    "                \"algo\": algo\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60bb10add66f40fbbd52f97f4f9058e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ressum = None\n",
    "resraw = []\n",
    "\n",
    "for i, config in enumerate(tqdm(configs)):\n",
    "    results = modeler(df, target=\"Survived\", n=7, **config)\n",
    "    resraw.append(results)\n",
    "    summary = pd.DataFrame(results).describe()\n",
    "    if ressum is None:\n",
    "        ressum = summary\n",
    "    else:\n",
    "        ressum = pd.concat([ressum, summary], axis=1, join=\"inner\")\n",
    "        ressum.columns = [j for j in range(i + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin'],\n",
       " ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin'],\n",
       " ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin'],\n",
       " ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin'],\n",
       " ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin'],\n",
       " ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin'],\n",
       " ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin'],\n",
       " ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin']]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ressum.transpose()\n",
    "ressum.transpose().iloc[168]\n",
    "[config['drop'] for config in configs[168:176]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropsets = [\n",
    "    ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "]\n",
    "\n",
    "preProcessors = [\n",
    "    make_pipeline(StandardScaler(), SimpleImputer()),\n",
    "    make_pipeline(StandardScaler(), SimpleImputer(strategy=\"median\")),\n",
    "    make_pipeline(StandardScaler(), SimpleImputer(strategy=\"most_frequent\")),\n",
    "    make_pipeline(StandardScaler(), SimpleImputer(strategy=\"constant\", fill_value=-1)),\n",
    "    make_pipeline(RobustScaler(), SimpleImputer()),\n",
    "    make_pipeline(RobustScaler(), SimpleImputer(strategy=\"median\")),\n",
    "    make_pipeline(RobustScaler(), SimpleImputer(strategy=\"most_frequent\")),\n",
    "    make_pipeline(RobustScaler(), SimpleImputer(strategy=\"constant\", fill_value=-1)),\n",
    "]\n",
    "\n",
    "algos = [\n",
    "    GradientBoostingClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    BernoulliNB(),\n",
    "    KNeighborsClassifier(),\n",
    "]\n",
    "\n",
    "configs = []\n",
    "for dropset in dropsets:\n",
    "    for preProc in preProcessors:\n",
    "        for algo in algos:\n",
    "            configs.append({\n",
    "                \"drop\": dropset,\n",
    "                \"preProcess\": preProc,\n",
    "                \"algo\": algo\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36fcde200a446018f52ac5c22e7af76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ressum = None\n",
    "resraw = []\n",
    "\n",
    "for i, config in enumerate(tqdm(configs)):\n",
    "    results = modeler(df, target=\"Survived\", n=7, **config)\n",
    "    resraw.append(results)\n",
    "    summary = pd.DataFrame(results).describe()\n",
    "    if ressum is None:\n",
    "        ressum = summary\n",
    "    else:\n",
    "        ressum = pd.concat([ressum, summary], axis=1, join=\"inner\")\n",
    "        ressum.columns = [j for j in range(i + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'drop': ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin'], 'preProcess': Pipeline(steps=[('robustscaler', RobustScaler()),\n",
      "                ('simpleimputer', SimpleImputer())]), 'algo': GradientBoostingClassifier()}\n",
      "{'drop': ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin'], 'preProcess': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('simpleimputer', SimpleImputer())]), 'algo': GradientBoostingClassifier()}\n"
     ]
    }
   ],
   "source": [
    "for i in [16, 0]:\n",
    "    print(configs[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropsets = [\n",
    "    ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "]\n",
    "\n",
    "preProcessors = [\n",
    "    make_pipeline(StandardScaler(), SimpleImputer()),\n",
    "    make_pipeline(RobustScaler(), SimpleImputer()),\n",
    "]\n",
    "\n",
    "algos = [\n",
    "    GradientBoostingClassifier(),\n",
    "]\n",
    "\n",
    "configs = []\n",
    "for dropset in dropsets:\n",
    "    for preProc in preProcessors:\n",
    "        for algo in algos:\n",
    "            configs.append({\n",
    "                \"drop\": dropset,\n",
    "                \"preProcess\": preProc,\n",
    "                \"algo\": algo\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bff479d2ce4cc68f70f6e9e29427e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ressum = None\n",
    "resraw = []\n",
    "\n",
    "for i, config in enumerate(tqdm(configs)):\n",
    "    results = []\n",
    "    for j in range(30):\n",
    "        results.extend(modeler(df, target=\"Survived\", n=7, **config))\n",
    "    resraw.append(results)\n",
    "    summary = pd.DataFrame(results).describe()\n",
    "    if ressum is None:\n",
    "        ressum = summary\n",
    "    else:\n",
    "        ressum = pd.concat([ressum, summary], axis=1, join=\"inner\")\n",
    "        ressum.columns = [j for j in range(i + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210.0</td>\n",
       "      <td>0.845798</td>\n",
       "      <td>0.032096</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.826772</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>0.905512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210.0</td>\n",
       "      <td>0.844635</td>\n",
       "      <td>0.030002</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.826772</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>0.897638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count      mean       std       min       25%       50%       75%       max\n",
       "0  210.0  0.845798  0.032096  0.796875  0.826772  0.834646  0.874016  0.905512\n",
       "1  210.0  0.844635  0.030002  0.796875  0.826772  0.834646  0.874016  0.897638"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ressum.transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc9a96f63e561c3d59894d367fe6edafcf442dbb31cb080741455c33b297d923"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
