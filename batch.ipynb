{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from math import ceil\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"dataset\\train.csv\"\n",
    "df= pd.read_csv(path)\n",
    "preProcessor = make_pipeline(StandardScaler(), SimpleImputer())\n",
    "model = GradientBoostingClassifier()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticketNo(ticketStr):\n",
    "    if isinstance(ticketStr, str):\n",
    "        noStr = re.findall(r\"[0-9]*$\", ticketStr)[0]\n",
    "        if noStr.isnumeric():\n",
    "            return int(noStr)\n",
    "    return np.nan\n",
    "\n",
    "def ticketTxt(ticketStr):\n",
    "    if isinstance(ticketStr, str):\n",
    "        noStr = re.findall(r\"[0-9]*$\", ticketStr)[0]\n",
    "        return ticketStr[:-len(noStr)]\n",
    "    return np.nan\n",
    "\n",
    "df[\"ticketNo\"] = df[\"Ticket\"].apply(ticketNo)\n",
    "df[\"ticketTxt\"] = df[\"Ticket\"].apply(ticketTxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cabinNo(cabinStr):\n",
    "    if isinstance(cabinStr, str):\n",
    "        return re.findall(r\"[0-9]*$\", cabinStr)[0]\n",
    "    return np.nan\n",
    "\n",
    "def cabinLvl(cabinStr):\n",
    "    if isinstance(cabinStr, str):\n",
    "        return re.findall(r\"^[A-Z]\", cabinStr)[0]\n",
    "    return np.nan\n",
    "\n",
    "df[\"cabinLvl\"] = df[\"Cabin\"].apply(cabinLvl)\n",
    "df[\"cabinNo\"] = df[\"Cabin\"].apply(cabinNo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title(name):\n",
    "    if isinstance(name, str):\n",
    "        return re.findall(r\"\\b\\w*\\.\", name)[0]\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "df[\"surname\"] = df[\"Name\"].apply(lambda x: x.split(\",\")[0])\n",
    "df[\"withChild\"] = df[\"Name\"].apply(lambda x: \"(\" in x)\n",
    "df[\"title\"] = df[\"Name\"].apply(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Categorical Features\n",
    "for col in df.columns:\n",
    "    if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "        df[col] = df[col].map({key: val for val, key in enumerate(df[col].unique())})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeler(df, target, drop=None, n=1, testSize=0.3, preProcess=None, algo=DummyClassifier(), metric=accuracy_score):\n",
    "    dfi = df.copy()\n",
    "    if drop:\n",
    "        dfi = dfi.drop(columns=drop)\n",
    "    \n",
    "    X = dfi.drop(columns=[target])\n",
    "    y= dfi[target]\n",
    "    results = []\n",
    "    \n",
    "    for train, test in KFold(n_splits=n, shuffle=True, random_state=42).split(X, y):\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "        if preProcess:\n",
    "            X_train = preProcess.fit_transform(X_train)\n",
    "            X_test = preProcess.transform(X_test)\n",
    "        algo.fit(X_train, y_train)\n",
    "        results.append(metric(y_test, algo.predict(X_test)))\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [\"ticketNo\", \"ticketTxt\", \"cabinLvl\", \"cabinNo\", \"surname\", \"withChild\",]\n",
    "dropsets = []\n",
    "for i in range(len(options)+1):\n",
    "    for combo in combinations(options, i):\n",
    "        combo = list(combo)\n",
    "        combo.extend([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"])\n",
    "        dropsets.append(combo)\n",
    "\n",
    "preProcessors = [\n",
    "    make_pipeline(StandardScaler(), SimpleImputer()),\n",
    "    make_pipeline(StandardScaler(), SimpleImputer(strategy=\"median\")),\n",
    "    make_pipeline(StandardScaler(), SimpleImputer(strategy=\"most_frequent\")),\n",
    "    make_pipeline(StandardScaler(), SimpleImputer(strategy=\"constant\", fill_value=-1)),\n",
    "    make_pipeline(RobustScaler(), SimpleImputer()),\n",
    "    make_pipeline(RobustScaler(), SimpleImputer(strategy=\"median\")),\n",
    "    make_pipeline(RobustScaler(), SimpleImputer(strategy=\"most_frequent\")),\n",
    "    make_pipeline(RobustScaler(), SimpleImputer(strategy=\"constant\", fill_value=-1)),\n",
    "]\n",
    "\n",
    "algos = [\n",
    "    GradientBoostingClassifier()\n",
    "]\n",
    "\n",
    "configs = []\n",
    "for dropset in dropsets:\n",
    "    for preProc in preProcessors:\n",
    "        for algo in algos:\n",
    "            configs.append({\n",
    "                \"drop\": dropset,\n",
    "                \"preProcess\": preProc,\n",
    "                \"algo\": algo\n",
    "            })\n",
    "# configs = configs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60bb10add66f40fbbd52f97f4f9058e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ressum = None\n",
    "resraw = []\n",
    "\n",
    "for i, config in enumerate(tqdm(configs)):\n",
    "    results = modeler(df, target=\"Survived\", n=7, **config)\n",
    "    resraw.append(results)\n",
    "    summary = pd.DataFrame(results).describe()\n",
    "    if ressum is None:\n",
    "        ressum = summary\n",
    "    else:\n",
    "        ressum = pd.concat([ressum, summary], axis=1, join=\"inner\")\n",
    "        ressum.columns = [j for j in range(i + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin'],\n",
       " ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin'],\n",
       " ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin'],\n",
       " ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin'],\n",
       " ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin'],\n",
       " ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin'],\n",
       " ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin'],\n",
       " ['surname', 'withChild', 'PassengerId', 'Name', 'Ticket', 'Cabin']]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ressum.transpose()\n",
    "ressum.transpose().iloc[168]\n",
    "[config['drop'] for config in configs[168:176]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc9a96f63e561c3d59894d367fe6edafcf442dbb31cb080741455c33b297d923"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
